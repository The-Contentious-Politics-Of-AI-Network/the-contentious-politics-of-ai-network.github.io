# Regular resistance updates

In an attempt to challenge what we term the 'inevitability narrative' we circulate regular monthly updates on the range of forms of anti-AI activity as they occur. To receive these newsletters, join our network.

They are reproduced here below:

October 2024

At the micro-level we continue to see an ongoing series of everyday forms of 'misbehaviour' or subversion regarding the use of AI. A recent survey of company employees found that over 30% were actively sabotaging their company's AI strategy, with the most likely reason given that the introduction of AI amounted to an explicit attempt to subvert the attempt to replace employee's jobs. Reflecting this trend, a recent McKinsey report that while 80% of companies are introducing gen AI in some form, at the same time around 80% also report no improvement on their bottom line as a result of introducing AI; the report identifies a key reason as "implicit resistance from business teams and middle management due to fear of disruption, uncertainty around job impact, and lack of familiarity with the technology.". Likewise, the NYT reported on attempts by job applicants to trick chatbot recruiters for job applications.  The Information reports on how coders are refusing to use AI tools to code, with two software engineers at Mixus, San Francisco, staging a rebellion by refusing to follow instructions to rely on AI coding-assistance software. Higher up the hierarchy within AI companies, the FT reported an exodus from disgruntled senior staff from Musk's xAI.  Also as a result of worker opposition, Microsoft announced it would disable some services to Israel’s Defense Ministry, after a company review concluded that Israel was using Microsoft’s cloud storage services to hold surveillance data on Palestinians - this came after disgruntled employees entered company president, Brad Smith’s office, to protest, hang banners and occupy rooms in the company HQ.

In terms of regulation, we have seen a number of key developments. This includes the introduction of the new California AI Companion Law (SB243), as this piece from James Muldoon reports. Newsom also signed the first AI Safety Law (SB53) in California - as also reported in more detail here by techcrunch- although he also vetoed another piece of legislation (AB1064) that sought to restrict access to AI for children. An AI Risk Evaluation Act was introduced into the US Senate. The much-vaunted UK's AI Bill also still remains waiting in the pipeline. Calls for further regulations were also voiced. Perhaps most visibly, the Global Call for AI Red Lines saw over 300 prominent figures call for governments to reach international agreements regarding red lines for AI. Similarly, a group of leading experts in Cognitive Sciences signed an Open Letter called for the rejection of the uncritical introduction of AI in academia. For a more global summary of AI policies and regulations, do see the excellent new Artificial Intelligence Policy Observatory for the World of Work (AIPOWW) Symposium in the current issue of the journal, Global Political Economy. This reports on the work of the Artificial Intelligence Policy Observatory for the World of Work, based at University of Essex’s Centre for Commons Organising, Values Equalities and Resilience and which is led by Phoebe V. Moore and Peter Bloom (both members of our Contentious Politics Of AI Network). It includes excellent commentaries on AI policies and regulations in the EU, Brazil, India, China, and Canada.

The wider impact of AI-related infrastructure is also being contested. Efforts to oppose the building of data centres are growing in prominence. Earlier this year saw reports of the Sierra Club seeking to overturn the licence for a data centre as part of their campaign in Reno, Nevada. MIT Technology Review covered a  related campaign by the Pyramid Lake Paiute Tribe to tackle the use of water by data centres that threatens to divert it away from the Pyramid Lake. More generally, the impact of AI on energy costs is starting to have political consequences. With voters increasingly calling for political measures to offset or reduce the impact of AI energy use on household energy costs. In the US, Democrats, led by Elizabeth Warren, have sought to politicise the issue and called for Trump to act. A recent election in Virginia saw both the Democrat and Republican candidates cite the rise in electricity costs as a key reason why the building of any new data centres should be blocked. This reflects a more general trend whereby public opinion in the US is becoming increasingly sceptical about the merits of AI. As the Atlantic reports, the ongoing negative public opinion of Musk continues to have a detrimental impact on the introduction of AI technologies with Tesla.

Finally, in terms of legal challenges, Anthropic agreed a much-reported $1.5billion copyright settlement to resolve the copyright class action brought against it.
