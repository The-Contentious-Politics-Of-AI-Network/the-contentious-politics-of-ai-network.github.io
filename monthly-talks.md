---
---


{% include nav.html %}


<!-- 
# The Contentious Politics Of AI
Our network offers a space for those who want to research, study, and make visible (and possible) ways that AI is, and can be, challenged. 

It is open to all -  academics, policy researchers, and activists interested in ways that AI is contested - see details below on how to sign up. -->

# Monthly contestation updates

Since our launch we have begun to produce a running update in newsletter form of the different types of contestation as they happen and are reported. [Sign-up to our email list](https://www.jiscmail.ac.uk/cgi-bin/wa-jisc.exe?SUBED1=CONTENTIOUS-AI-POLITICS) to receive these once they are produced.

**November/December** 

Data centres continue to be a major target of public opposition, especially in the US, and over the pollution for local residents and water and electricity use. Amazon was under pressure after being [found](https://www.theguardian.com/technology/2025/oct/25/amazon-datacentres-water-use-disclosure) to have actively sought to keep the water use of its data centres secret. As Harvard Business Review [reports](https://hbr.org/2025/11/mitigating-the-public-health-impacts-of-ai-data-centers), some state agencies have begun conducting health impact assessments of data centers’ on-site diesel generators to inform emission limits. [Bloomberg](https://archive.is/20250929234947/https://www.bloomberg.com/graphics/2025-ai-data-centers-electricity-prices) carry a report claiming that electricity prices have doubled since 2020, with the highest rate of increase in locations that are within 50 miles of a data centre - all of which is creating considerable public anger. Elections are increasingly focused on candidates' positions on data centres: a recent [election in Northern Virginia](https://www.washingtonpost.com/dc-md-va/2025/11/08/prince-william-county-gainseville-election/) witnessing both candidates pledge to block the expansion of data centres, and with the vote seemingly going to the candidate who was most ardent in his opposition. This comes amid reports of America's coming war on data centres [here](https://archive.is/20251208132716/https://www.vox.com/technology/471138/ai-data-centers-electricity-prices-populist-backlash-explained). The campaign organisation, Data Centre Watch, produced a report highlighting how [$64 billion in U.S. data center projects](https://archive.is/LdECp) have been blocked or delayed by a growing wave of local, bipartisan opposition since 2024. Also see more details of the [ongoing campaign by the  Pyramid Lake Paiute Tribe](https://www.theguardian.com/technology/2025/dec/04/nevada-ai-data-centers) to oppose the building of data centres in the region. 230 environmental groups [demanded](https://www.theguardian.com/us-news/2025/dec/08/us-data-centers) a national moratorium on new datacenters in the US. This is alongside a [new online campaign](https://www.savepennsylvania.com/) to oppose the building of data centres in Pennsylvania. At the same time, Amazon has [complained](https://archive.is/Cy3KP) to the the Public Utility Commission of Oregon alleging that Portland-based PacifiCorp is failing to provide enough electricity to its data centre! 

Worker and employee resistance and opposition to AI also continues. Ex-AI product safety lead, Steven Adler, [broke ranks](https://www.nytimes.com/2025/10/28/opinion/openai-chatgpt-safety.html) with the firm to highlight the continued risk of serious mental health issues associated with the use of AI chatbots. Likewise, the Guardian [reports from a range of AI workers](https://www.theguardian.com/technology/2025/nov/22/ai-workers-tell-family-stay-away) and raters who report the flawed models of AI training and speak out against the use of AI. For a broader discussion, see this [Podcast](https://therealnews.com/workers-replaced-by-ai-have-a-dire-warning) by two founders of a new mutual aid and advocacy group called Stop Gen AI, which formed this year out of the critical need to provide material support for creatives, knowledge workers, and anyone else impacted by generative AI.  [Research by Deloitte](https://hbr.org/2025/11/workers-dont-trust-ai-heres-how-companies-can-change-that) found that employee's trust in their employer's AI tools is dramatically falling - by 31% in the most recent findings. Quartz [reports](https://qz.com/microsoft-copilot-rage) widespread hatred towards MS Copilot, in part due to employers forcing its adoption upon employees, prompting widespread [online mockery](https://www.reddit.com/r/technology/comments/1p92qzs/you_heard_wrong_users_brutually_reject_microsofts/) and reports that MS is now needing to [downgrade](https://archive.is/20251210131901/https://www.theinformation.com/articles/microsoft-lowers-ai-software-sales-quotas-customers-resist-newer-products) sales expectations.

The impact of AI on worker productivity has also been questioned. [Research](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/) into the use of AI by software developers found that it made them 19% slower than when they worked without AI - yet despite this they believed that AI had sped them up by 20%.

AI has also faced ongoing legal challenges. In Japan, Yomiuri Shimbun and the Asahi Shimbun have [filed](https://www.japantimes.co.jp/business/2025/10/29/companies/kddi-responsible-ai/) a lawsuit with the Tokyo District Court in August against U.S. AI startup Perplexity AI; Amazon also [sued](https://archive.is/VBQIX) Perplexity in an attempt to stop its chatbot from shopping on its platform. OpenAI was [sued](https://www.reuters.com/legal/litigation/openai-sued-trademark-infringement-over-soras-cameo-feature-2025-10-28/) by firm Cameo, with OpenAI accused of deliberately confusing consumers by introducing a new "Cameo" feature on Sora; a [series of lawsuits by OpenAI chatbot users ](https://www.nytimes.com/2025/11/06/technology/chatgpt-lawsuit-suicides-delusions.html)for suicides and harmful delusions - confirming media reports of a trend of mental health [hospitalizations](https://archive.is/CtvuJ) as a result of chatbot use. A lawsuit was [filed](https://www.washingtonpost.com/business/2025/12/01/ai-work-regulations-california) in California against discriminatory recruitment practices as a result of AI decision-making. A lawsuit was [brought](https://www.washingtonpost.com/technology/2025/12/11/chatgpt-murder-suicide-soelberg-lawsuit) against OpenAI claims ChatGPT persuaded a user to kill his mother and himself. The European Commission [announced](https://euobserver.com/rule-of-law/ar934ed122) an investigation into Google's AI overview feature.

AI firms are being forced to act as a result of these legal challenges. For instance, the fallout from an earlier adverse legal ruling against it prompted Character.AI to move to [ban](https://www.nytimes.com/2025/10/29/technology/characterai-underage-users.html) children under 18 from using its chatbots.

Not only AI firms, but also AI users have faced legal challenges. Most notably, courts in Utah, Indiana and California have [fined](https://www.washingtonpost.com/nation/2025/06/03/attorneys-court-ai-hallucinations-judges) lawyers for using AI-generated legal submissions that included hallucinations reporting non-existent research and case law. 

In terms of AI regulations, family-led campaigns over the risks of AI chatbots have featured heavily in recent weeks. Senators Hawley and Blumenthal have [proposed legislation](https://www.nbcnews.com/tech/tech-news/ai-ban-kids-minors-chatgpt-characters-congress-senate-rcna240178) passing through US Congress seeks to limit availability of chatbots to minors, following [pressure](https://www.nbcnews.com/tech/tech-news/parents-testify-impact-ai-chatbots-children-are-not-experiments-rcna231787) from parents of children who have taken their own lives under the influence of chatbots. The UK government also [announced](https://www.ft.com/content/12cc60ef-7d97-4d20-a7fd-9a28ff6bcb11) that it is considering new laws regulating the use of AI chatbots by children. In addition, China [adopted](https://archive.is/KVPqI) regulation designed to restrict fake images and videos, adding to existing legislation which requires AI-related companies to use generative AI services in line with the values of socialism (and which already governs the design and use of DeepSeek). A [new law in New York](https://www.nytimes.com/2025/11/29/nyregion/personalized-surveillance-pricing-ai-new-york.html) regulates the use of AI to develop personalised pricing. The  Data (Use and Access) Act 2025 was adopted in the UK, banning deepfake porn and making it a criminal offence, [prompted](https://www.theguardian.com/society/ng-interactive/2025/dec/04/i-dont-take-no-for-an-answer-how-a-small-group-of-women-changed-the-law-on-deepfake-porn) by a feminist campaign group make up of victims of deepfake porn and experts. 

As the UK Government continues to consider AI-related copyright law, Paul McCartney [contributed](https://www.theguardian.com/music/2025/nov/17/the-sound-of-silence-why-theres-barely-anything-there-in-paul-mccartney-new-release) to ongoing objections from the music industry regarding the infringement of copyright by AI firms, releasing a track of an almost completely silent recording studio, to highlight what the music industry might become if copyright laws aren't updated to take account of AI.

Schools and parents are becoming increasingly focused on the risks of AI, with a [parent-led campaign](https://neighborhoodview.org/2025/11/13/digital-future-or-risk-to-critical-thinking-skills-5-takeaways-as-malden-drafts-ai-strategy-for-schools/) creating pressures on Malden Public Schools and demanding better regulation, with many parents calling for an outright ban in schools.

A broader anti-AI sentiment can also be discerned in terms of public opinion and how this is translating into political pressure, and forcing firms and organisations to reconsider their approach to AI. [Research](https://academic.oup.com/pa/advance-article/doi/10.1093/pa/gsaf050/8300196) into the degree to which the public trusted AI to allow politicians to take decision was overwhelmingly opposed in both the UK and Japan. Google was [forced](https://www.engadget.com/ai/google-removes-ai-model-after-it-allegedly-accused-a-senator-of-sexual-assault-170235679.html) to remove its  AI model Gemma from its Studio platform after a Republican senator said it "fabricated serious criminal allegations" against her. The academic paper publishing platform, arXiv, [announced](https://www.404media.co/arxiv-changes-rules-after-getting-spammed-with-ai-generated-research-papers/) it will no longer accept computer science review articles and position papers due to the overwhelmingly high level of "AI slop" that was being submitted to the platform. McDonald’s faced [online opposition ](https://www.forbes.com/sites/danidiplacido/2025/12/09/mcdonalds-ai-generated-ad-controversy-explained)to its AI-generated Christmas advert, forcing the firm to turn off comments on YouTube, before setting the video to private.

In terms of political consequences, [divisions](https://www.ft.com/content/e087e732-5f71-4db3-b613-830f3cee313d) within the MAGA camp have emerged following Trump's backing for a plan to restrict state-level regulation of AI, with Ron DeSantis calling Trump's plan “an insult to voters” (another similar [report](https://www.washingtonpost.com/politics/2025/11/24/afpi-ai-plan-trump-tech) in the Washington Post). As well as divisions within Meta, with [reports](https://www.nytimes.com/2025/12/10/technology/meta-ai-tbd-lab-friction.html) of a schism between the AI team and the rest.

A number of other campaign developments: The Verge [reports](https://www.theverge.com/ai-artificial-intelligence/829813/ai-agi-pope-leo) a campaign seeking to influence the Pope to speak out against the risks of AGI. A detailed set of [recommendations](https://wagingnonviolence.org/2025/12/palestine-movement-outsmarting-algorithms/) for campaign organisations seeking to use social media platforms in a way that outsmarts algorithms designed to minimise the visibility of Palestine solidarity campaigns. The [campaign](https://controlai.com/statement) by ControlAI to ask UK-based MPs to sign a pledge calling for "binding regulation on the most powerful AI systems" [reached](https://www.theguardian.com/technology/2025/dec/08/scores-of-uk-parliamentarians-join-call-to-regulate-most-powerful-ai-systems) 100 MPs signed up.

The European Conference on AI ([ECAI](https://ecai2025.org/)) which took place in Bologna in October 2025 witnessed a [demonstration](https://www.instagram.com/p/DQMnuy4jPRR/?img_index=1) staged by local Palestine solidarity activists and organisations, which took place outside the Conference, declaring that such conferences are 'just advertising stores for criminal multinational companies that finance the development of new technologies, devices placed on the market with the label "for civil use", and then sold to the "defense" sector, to companies like Leonardo S.p.a., that still export weapons to "Israel". The production of genocide begins in European classrooms, laboratories and research centers: ECAI is the emblem of neoliberal hypocrisy, the same one that tries to hide death and destruction behind empty principles of peace, freedom and democracy'.

For more summaries of contemporary anti-AI campaigns, see this nice [article](https://archive.is/lowlU) in Vox listing some of the most impressive recent achievements for anti-AI campaigns. And another similarly good [overview](https://mronline.org/2025/11/17/data-center-resistance-a-good-ground-game-can-help-stop-the-corporate-ai-offensive/) of some recent campaign successes in this article in MROnline. 




**October 2025**

At the micro-level we continue to see an ongoing series of everyday forms of 'misbehaviour' or subversion regarding the use of AI. A recent survey of company employees found that [over 30% were actively sabotaging their company's AI strategy](https://urldefense.com/v3/__https://www.cio.com/article/4022953/31-of-employees-are-sabotaging-your-gen-ai-strategy.html__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-06aKa1w$), with the most likely reason given that the introduction of AI amounted to an explicit attempt to subvert the attempt to replace employee's jobs. Reflecting this trend, a recent McKinsey [report](https://urldefense.com/v3/__https://www.mckinsey.com/capabilities/quantumblack/our-insights/seizing-the-agentic-ai-advantage__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9CgqtcGw$) that while 80% of companies are introducing gen AI in some form, at the same time around 80% also report no improvement on their bottom line as a result of introducing AI; the report identifies a key reason as "implicit resistance from business teams and middle management due to fear of disruption, uncertainty around job impact, and lack of familiarity with the technology.". Likewise, the NYT [reported](https://urldefense.com/v3/__https://www.nytimes.com/2025/10/07/business/ai-chatbot-prompts-resumes.html__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C_Q4RkqEA$) on attempts by job applicants to trick chatbot recruiters for job applications.  The Information [reports](https://urldefense.com/v3/__https://archive.is/ggXs4*selection-1275.0-1275.237__;Iw!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9rDRTprg$) on how coders are refusing to use AI tools to code, with two software engineers at Mixus, San Francisco, staging a rebellion by [refusing](https://urldefense.com/v3/__https://archive.is/ggXs4*selection-1275.0-1275.237__;Iw!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9rDRTprg$) to follow instructions to rely on AI coding-assistance software. Higher up the hierarchy within AI companies, the FT [reported](https://urldefense.com/v3/__https://www.ft.com/content/21ec5a5f-0e9a-49b9-b64d-9ebc88e70aa7__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8MqUuHTA$) an exodus from disgruntled senior staff from Musk's xAI.  Also as a result of worker opposition, Microsoft [announced](https://urldefense.com/v3/__https://www.nytimes.com/2025/09/25/technology/microsoft-israel-defense-ministry.html__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9k5T0BKw$) it would disable some services to Israel’s Defense Ministry, after a company review concluded that Israel was using Microsoft’s cloud storage services to hold surveillance data on Palestinians - this came after disgruntled employees entered company president, Brad Smith’s office, to protest, hang banners and occupy rooms in the company HQ.

In terms of regulation, we have seen a number of key developments. This includes the introduction of the new California AI Companion Law (SB243), as this [piece](https://urldefense.com/v3/__https://doesnotcomputeai.substack.com/p/california-passes-the-worlds-first__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-i-lKlGA$) from James Muldoon reports. Newsom also [signed](https://urldefense.com/v3/__https://www.politico.com/news/2025/09/29/newsom-signs-ai-law-00585348__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C_16jiACA$) the first AI Safety Law (SB53) in California - as also [reported](https://urldefense.com/v3/__https://techcrunch.com/2025/09/29/california-governor-newsom-signs-landmark-ai-safety-bill-sb-53/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9QJy0dzg$) in more detail here by techcrunch- although he also [vetoed](https://urldefense.com/v3/__https://thehill.com/policy/technology/5553487-newsom-signs-ai-safety-bill/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8fZFqKdw$) another piece of legislation (AB1064) that sought to restrict access to AI for children. An AI Risk Evaluation Act was [introduced](https://urldefense.com/v3/__https://controlai.news/p/before-the-cliff-regulating-ai__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9E_Z_pcw$) into the US Senate. The much-vaunted UK's AI Bill also still remains [waiting](https://urldefense.com/v3/__https://controlai.news/p/before-the-cliff-regulating-ai__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9E_Z_pcw$) in the pipeline. Calls for further regulations were also voiced. Perhaps most visibly, the [Global Call for AI Red Lines](https://urldefense.com/v3/__https://red-lines.ai/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-2XzNhjw$) saw over 300 prominent figures call for governments to reach international agreements regarding red lines for AI. Similarly, a group of leading experts in Cognitive Sciences [signed an Open Letter](https://urldefense.com/v3/__https://zenodo.org/records/17065099__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9KAYJV0g$) called for the rejection of the uncritical introduction of AI in academia. For a more global summary of AI policies and regulations, do see the excellent new Artificial Intelligence Policy Observatory for the World of Work (AIPOWW) Symposium in the [current issue](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/gpe.4.issue-2.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8iWLkSKQ$) of the journal, Global Political Economy. This reports on the work of the Artificial Intelligence Policy Observatory for the World of Work, based at University of Essex’s Centre for Commons Organising, Values Equalities and Resilience and which is led by Phoebe V. Moore and Peter Bloom (both members of our Contentious Politics Of AI Network). It includes excellent commentaries on AI policies and regulations in the [EU](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/article-p201.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C_p_J1-AQ$), [Brazil](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/article-p215.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C_vtEqOIw$), [India](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/article-p228.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8eiMUOQg$), [China](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/article-p243.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8cfH4I7w$), and [Canada](https://urldefense.com/v3/__https://bristoluniversitypressdigital.com/view/journals/gpe/4/2/article-p256.xml__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C_qAlosow$).

The wider impact of AI-related infrastructure is also being contested. Efforts to oppose the building of data centres are growing in prominence. Earlier this year saw reports of the Sierra Club seeking to overturn the licence for a data centre as part of their [campaign](https://urldefense.com/v3/__https://nevadacurrent.com/2025/01/10/effort-to-block-reno-data-center-offers-glimpse-of-increasingly-thorny-issue-in-nevada/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C9Q6A8Kmw$) in Reno, Nevada. MIT Technology Review covered a  related [campaign](https://urldefense.com/v3/__https://www.technologyreview.com/2025/05/20/1116287/ai-data-centers-nevada-water-reno-computing-environmental-impact/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-XYQTdFA$) by the Pyramid Lake Paiute Tribe to tackle the use of water by data centres that threatens to divert it away from the Pyramid Lake. More generally, the impact of AI on energy costs is starting to have political consequences. With voters increasingly calling for political measures to offset or reduce the impact of AI energy use on household energy costs. In the US, Democrats, led by Elizabeth Warren, have sought to politicise the issue and [called](https://urldefense.com/v3/__https://archive.is/0aBqV__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C__kGx4mw$) for Trump to act. A recent election in Virginia saw both the Democrat and Republican candidates cite the rise in electricity costs as a key reason why the building of any new data centres should be [blocked](https://urldefense.com/v3/__https://www.semafor.com/article/10/13/2025/as-electricity-bills-rise-candidates-in-both-parties-blame-data-centers__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C8ja4ioSA$). This reflects a more general trend whereby [public opinion](https://urldefense.com/v3/__https://www.washingtonpost.com/technology/2025/10/07/ai-public-opinion-mistrust__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-8TNKFyg$) in the US is becoming increasingly sceptical about the merits of AI. As the Atlantic [reports](https://urldefense.com/v3/__https://www.theatlantic.com/technology/2025/10/cheaper-tesla-elon-musk-trump/684528/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-SIQ57yA$), the ongoing negative public opinion of Musk continues to have a detrimental impact on the introduction of AI technologies with Tesla.

Finally, in terms of legal challenges, Anthropic agreed a much-reported $1.5billion copyright [settlement](https://urldefense.com/v3/__https://www.reuters.com/sustainability/boards-policy-regulation/us-judge-approves-15-billion-anthropic-copyright-settlement-with-authors-2025-09-25/__;!!CF15FET90Tp8!Dzz4DY7fBf9sPwFhJhRD-iGU0xk1hRwxvLyTRK37Vp0G3ubDhPKklH3GW-EW1z5lCP95py811hD93tCCJFauT8porePN7C-vL3gzWw$) to resolve the copyright class action brought against it.



### Contact

The Contentious Politics Of AI network is coordinated by [David J. Bailey](https://www.birmingham.ac.uk/staff/profiles/gov/bailey-david) (University of Birmingham), [Masoumeh (Iran) Mansouri](https://www.birmingham.ac.uk/staff/profiles/computer-science/academic-staff/masoumeh-mansouri) (University of Birmingham), and [Gary Smith](https://www.linkedin.com/in/dr-gary-smith-mbcs/) 

If you have any questions or want to get involved, email us at contestingAInetwork@gmail.com
