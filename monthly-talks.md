---
---


{% include nav.html %}

## Upcoming Monthly Talks

**21 January 2026, 3pm (GMT)
The AI Matrix: Profits, Politics, and the Struggle Over Our Tech Future**
Speakers: [Regine Paul](https://www4.uib.no/en/find-employees/Regine.Paul) and [Vali Stan](https://www.uva.nl/en/profile/s/t/v.a.stan2/v.a.stan.html)

This talk will introduce the new book, The AI Matrix: Profits, Power, Politics - available open access ([https://www.agendapub.com/page/detail/the-ai-matrix/?k=9781788218597](https://www.agendapub.com/page/detail/the-ai-matrix/?k=9781788218597)).

Register here: [https://bham-ac-uk.zoom.us/meeting/register/c7ukzey4SVOoQ1MgnsC7lA](https://bham-ac-uk.zoom.us/meeting/register/c7ukzey4SVOoQ1MgnsC7lA)

AI is often presented in extremes, either as a revolutionary technology boosting prosperity for everyone, or as a juggernaut that threatens jobs, democracy, or even human life. This talk cuts through those narratives by asking a simpler question: who really benefits from AI, and who has the power to shape how it is made and used? Drawing on a critical political economy perspective, we argue that today’s AI boom is not simply about clever machines taking over, but about profit imperatives and political choices. AI technologies are developed and deployed within pre-existing economic structures, largely reinforcing inequalities between industries, workers, and countries rather than transforming them away.

Acknowledgement of this distinct socio-economic embedding of a hyped technology informs our search for forms of resistance. Contrary to the techno-determinist idea that the spread of AI is inevitable, and based on our recent co-authored book “[The AI Matrix](https://www.agendapub.com/page/detail/the-ai-matrix/?k=9781788218597)”, we present growing efforts to push back against the harmful and extractive uses of such technologies. These include workers challenging algorithmic surveillance and automation efforts, activists exposing the socio-ecological costs hidden in AI value chains, whistleblowers publicising biased systems and opaque business decisions, but also technicians experimenting with alternative, more public-interest-driven and less extractive forms of AI. Together, these emerging critical engagements with mainstream big tech show that AI futures remain contested and ultimately open. Whether current tech developments deepen global inequalities or support fairer and more democratic societies therefore depends less on the technology itself than on the collective decisions we make about the role of AI in our economies and societies.


**18 February, 3pm (GMT)
Favel IA: AI, Participatory Action Research (PAR), and the Question of Empathy**
Speaker: [Andrea Medrado](https://experts.exeter.ac.uk/43090-andrea-medrado) 

Register here: [https://bham-ac-uk.zoom.us/meeting/register/x6yVfu34Qq2YcEzhgU1azQ](https://bham-ac-uk.zoom.us/meeting/register/x6yVfu34Qq2YcEzhgU1azQ)

This talk presents preliminary findings from the project Favel IA, which was co-designed with the Papo Reto Institute (IPR), a favela media activist and human rights organisation based in Rio de Janeiro. The project analyses a core question developed jointly with IPR: How does the favela use AI as opposed to how AI uses the favela in extractive ways? Drawing from critical and decolonial data and AI studies (Valente and Grohmann, 20024; Goodlad, 2023; Ricaurte, 2019), Favel IA interrogates the politics of empathy as a form of solidarity. It is also attentive to the gendered, raced, classed, and transnational geopolitical dimensions that shape who is permitted to perform empathy and who is positioned as its beneficiary. These dynamics contrast sharply with the everyday invisible forms of political empathy exercised by favela communities, which are rarely recognised or valued.

Favel IA employs participatory action research (PAR) as its main methodological approach, inspired by Latin American scholars such as Orlando Fals Borda (1987) and Paulo Freire (2002). The project involves three main groups: postgraduate students, favela media activists, and community leaders. The research team engaged participants in five consecutive days of workshops. We asked them to document their daily encounters with AI, to carry out empathy exercises and to reflect on critical questions about AI and data from a favela standpoint. Collectively, we also analysed existing and emerging AI regulation in Brazil and elsewhere and co-devised a conceptual note for policymakers, articulating the types of AI favela residents desire and the alternative futures that they envision.

The name Favel IA is a reference to the favelas themselves as forms of intelligence and to inteligência artificial, artificial intelligence in Portuguese. IÁ is also a common ending to many samba refrains (la iá la iá), evoking the idea that favela residents must “dance to the music” of AI systems designed by powerful private companies. While digital media platforms constrain agency, participants also identified instances of mundane resistance (Madianou, 2025), using generative AI to craft texts that signal socioeconomic mobility, employing AI tools to decode complex legislation and explain it for favela residents and/or using chatbots for emotional support. The latter, especially the use of AI as a therapist in contexts of grief caused by racist police violence, prompted critical debates about the myth of “empathetic AI.” These reflections culminated in a collective call to favelise AI, that is, to invert the centre-periphery relationship so that the lived experiences and voices off favela residents become central rather than marginal in AI debates and governance.

### Previous talks - 19 November 2025 - AI is on the march. Is the AI safety movement ready?

**Cathy Rogers, [Social Change Lab](https://www.socialchangelab.org/)
November 19th 2025, 3pm**

This is the first of a series of monthly talk hosted by the new Contentious Politics of AI network. The talk is on zoom and you can register for the talk [here](https://bham-ac-uk.zoom.us/meeting/register/Zp54HtA7RD22ZDQfMyhcnQ#/registration). The new report maps the emerging AI safety movement and finds critical gaps in grassroots mobilisation and public voice. The report is available [here](https://www.socialchangelab.org/ai-safety-movement) 
More details on Social Change Lab [here](https://www.socialchangelab.org/)
More details on the Contentious Politics of AI network are [here](https://the-contentious-politics-of-ai-network.github.io/) 

{% include youtube.html id="SzZAVydB4d0" %}

### Other Events and Opportunities

Watch this space - we will update accordingly.
